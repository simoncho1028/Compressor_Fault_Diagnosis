{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5749807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta\n",
    "from scipy.signal import stft, resample\n",
    "from typing import Dict, List, Tuple, Any\n",
    "\n",
    "#####################################\n",
    "# 1. ì„¤ì • í´ë˜ìŠ¤: ëª¨ë“  íŒŒë¼ë¯¸í„°ë¥¼ ì¤‘ì•™ì—ì„œ ê´€ë¦¬\n",
    "#####################################\n",
    "\n",
    "class Config:\n",
    "    \"\"\"\n",
    "    í”„ë¡œì íŠ¸ì˜ ëª¨ë“  ì„¤ì •ì„ ë‹´ëŠ” í´ë˜ìŠ¤\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # STFT íŒŒë¼ë¯¸í„°\n",
    "        self.fs = 80000\n",
    "        self.nperseg = 1024\n",
    "        self.hop_length = self.nperseg // 4\n",
    "        self.freq_limit = 1000\n",
    "        self.target_time_bins = 16\n",
    "\n",
    "        # ìœˆë„ìš° íŒŒë¼ë¯¸í„°\n",
    "        self.window_size_atoms = 5\n",
    "        self.step = 1\n",
    "        self.window_duration_seconds = self.window_size_atoms * 0.0102\n",
    "\n",
    "        # ë°ì´í„° ë¶„í•  íŒŒë¼ë¯¸í„°\n",
    "        self.block_size_seconds = 20\n",
    "        self.train_ratio = 0.6\n",
    "        self.val_ratio = 0.2\n",
    "\n",
    "        # ì…ì¶œë ¥ ë””ë ‰í† ë¦¬\n",
    "        self.output_stft_dir = \"processed_data_stft\"\n",
    "        self.output_raw_dir = \"processed_data_raw\"\n",
    "        \n",
    "        # ì…ë ¥ íŒŒì¼ ê²½ë¡œ\n",
    "        self.normal_files = {f\"normal_{i}\": f\"raw_data/normal/normal_{i}.csv\" for i in range(1, 21)}\n",
    "        self.abnormal_files = {\n",
    "            \"abnormal_1\": {f\"abnormal_1_{i}\": f\"raw_data/abnormal/abnormal_1_{i}.csv\" for i in range(1, 4)},\n",
    "            \"abnormal_2\": {f\"abnormal_2_{i}\": f\"raw_data/abnormal/abnormal_2_{i}.csv\" for i in range(1, 3)},\n",
    "            \"abnormal_3\": {f\"abnormal_3_{i}\": f\"raw_data/abnormal/abnormal_3_{i}.csv\" for i in range(1, 3)},\n",
    "            \"abnormal_4\": {f\"abnormal_4_{i}\": f\"raw_data/abnormal/abnormal_4_{i}.csv\" for i in range(3, 6)},\n",
    "        }\n",
    "        self.all_files = {\"normal\": self.normal_files, **self.abnormal_files}\n",
    "        \n",
    "        # ì¦ê°• ì„¤ì •\n",
    "        self.classes_to_augment = ['abnormal_1', 'abnormal_2']\n",
    "\n",
    "#####################################\n",
    "# 2. ê¸°ë³¸ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜: ë°ì´í„° ë¡œë“œ, ì›ì ì¶”ì¶œ, ìœˆë„ìš° ìƒì„± ë“±\n",
    "#####################################\n",
    "\n",
    "def load_data(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"CSV íŒŒì¼ì„ ì½ì–´ 'time' ì»¬ëŸ¼ì„ datetimeìœ¼ë¡œ ë³€í™˜ í›„ ì¸ë±ìŠ¤ë¡œ ì„¤ì •\"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['time'] = pd.to_datetime(df['time'], errors='coerce')\n",
    "    df.set_index(\"time\", inplace=True)\n",
    "    return df\n",
    "\n",
    "def group_atoms(data: pd.DataFrame) -> List[pd.DataFrame]:\n",
    "    \"\"\"ì›ì(Valid Pattern) ì¶”ì¶œ\"\"\"\n",
    "    data = data.copy().sort_index()\n",
    "    data['time_interval'] = data.index.to_series().diff().dt.total_seconds().fillna(0)\n",
    "    data['is_interval'] = (data['time_interval'] >= 0.7) & (data['time_interval'] <= 0.75)\n",
    "    data['is_vibration'] = data['time_interval'] < 0.1\n",
    "    data['group'] = data['is_interval'].cumsum()\n",
    "    \n",
    "    atoms = []\n",
    "    for _, group in data.groupby('group'):\n",
    "        if group['is_interval'].any() and group['is_vibration'].any():\n",
    "            atom = group[group['is_vibration']]\n",
    "            if len(atom) > 1:\n",
    "                atoms.append(atom)\n",
    "    return atoms\n",
    "\n",
    "def create_sliding_windows(atoms: List[pd.DataFrame], window_size: int, step: int) -> List[pd.DataFrame]:\n",
    "    \"\"\"ì›ì ë¦¬ìŠ¤íŠ¸ë¡œë¶€í„° ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ìƒì„±\"\"\"\n",
    "    return [pd.concat(atoms[i:i+window_size]) for i in range(0, len(atoms) - window_size + 1, step)]\n",
    "\n",
    "def augment_window(window: pd.DataFrame, augment_factor: int, methods=['noise', 'shift', 'scaling']) -> List[pd.DataFrame]:\n",
    "    \"\"\"ì£¼ì–´ì§„ ìœˆë„ìš°ì— ëŒ€í•´ ë°ì´í„° ì¦ê°• ìˆ˜í–‰\"\"\"\n",
    "    augmented_windows = []\n",
    "    data = window[['x', 'y', 'z']].values\n",
    "    for _ in range(augment_factor):\n",
    "        for method in methods:\n",
    "            if method == 'noise':\n",
    "                noise = np.random.normal(0, 0.01, data.shape)\n",
    "                aug_data = data + noise\n",
    "            elif method == 'shift':\n",
    "                shift = np.random.randint(1, int(data.shape[0] * 0.2) + 1)\n",
    "                aug_data = np.roll(data, shift, axis=0)\n",
    "            elif method == 'scaling':\n",
    "                scale = np.random.uniform(0.9, 1.1)\n",
    "                aug_data = data * scale\n",
    "            else:\n",
    "                aug_data = data.copy()\n",
    "            \n",
    "            aug_window = pd.DataFrame(aug_data, columns=['x', 'y', 'z'], index=window.index)\n",
    "            augmented_windows.append(aug_window)\n",
    "    return augmented_windows\n",
    "\n",
    "def get_time_segments_by_blocks(data: pd.DataFrame, config: Config) -> Dict[str, List[Tuple[pd.Timestamp, pd.Timestamp]]]:\n",
    "    \"\"\"ë°ì´í„°ë¥¼ 20ì´ˆ ë¸”ë¡ìœ¼ë¡œ ë‚˜ëˆ„ê³ , ê° ë¸”ë¡ì˜ train/val/test ì‹œê°„ êµ¬ê°„ ë°˜í™˜\"\"\"\n",
    "    segments = {'train': [], 'val': [], 'test': []}\n",
    "    total_seconds = (data.index[-1] - data.index[0]).total_seconds()\n",
    "\n",
    "    for i in range(int(total_seconds / config.block_size_seconds) + 1):\n",
    "        block_start = data.index[0] + timedelta(seconds=i * config.block_size_seconds)\n",
    "        block_end = block_start + timedelta(seconds=config.block_size_seconds)\n",
    "        block_data = data[(data.index >= block_start) & (data.index < block_end)]\n",
    "        \n",
    "        if len(block_data) > 0:\n",
    "            n = len(block_data)\n",
    "            train_end_idx = int(n * config.train_ratio)\n",
    "            val_end_idx = train_end_idx + int(n * config.val_ratio)\n",
    "            \n",
    "            if train_end_idx > 0:\n",
    "                segments['train'].append((block_data.index[0], block_data.index[train_end_idx - 1]))\n",
    "            if val_end_idx > train_end_idx:\n",
    "                segments['val'].append((block_data.index[train_end_idx], block_data.index[val_end_idx - 1]))\n",
    "            if n > val_end_idx:\n",
    "                segments['test'].append((block_data.index[val_end_idx], block_data.index[-1]))\n",
    "                \n",
    "    return segments\n",
    "\n",
    "#####################################\n",
    "# 3. ë°ì´í„° ë³€í™˜ ë° ì €ì¥ í•¨ìˆ˜\n",
    "#####################################\n",
    "\n",
    "def resample_window(window: pd.DataFrame, config: Config) -> pd.DataFrame:\n",
    "    \"\"\"ìœˆë„ìš°ë¥¼ target_fs ê¸°ì¤€ìœ¼ë¡œ ë¦¬ìƒ˜í”Œë§\"\"\"\n",
    "    num_samples = len(window)\n",
    "    end_time = num_samples / config.fs\n",
    "    new_time = np.arange(0, end_time, 1 / config.fs)\n",
    "    if len(new_time) < 2: return pd.DataFrame() # ë¦¬ìƒ˜í”Œë§ ë¶ˆê°€ ì¼€ì´ìŠ¤\n",
    "    \n",
    "    resampled_signal = resample(window[['x', 'y', 'z']].values, len(new_time), axis=0)\n",
    "    resampled_window = pd.DataFrame(resampled_signal, columns=['x', 'y', 'z'])\n",
    "    resampled_window['time'] = pd.to_datetime(new_time, unit='s')\n",
    "    return resampled_window.set_index('time')\n",
    "\n",
    "def window_to_stft_image(window: pd.DataFrame, config: Config) -> np.ndarray:\n",
    "    \"\"\"ìœˆë„ìš°ì—ì„œ STFT ì´ë¯¸ì§€(3ì±„ë„) ìƒì„±\"\"\"\n",
    "    noverlap = config.nperseg - config.hop_length\n",
    "    stft_images = []\n",
    "    for axis in ['x', 'y', 'z']:\n",
    "        f, t, Zxx = stft(window[axis].values, fs=config.fs, nperseg=config.nperseg, noverlap=noverlap)\n",
    "        freq_idx = f <= config.freq_limit\n",
    "        stft_img = np.abs(Zxx[freq_idx, :])\n",
    "        \n",
    "        # ì‹œê°„ ì¶• ê¸¸ì´ ë§ì¶”ê¸° (íŒ¨ë”© ë˜ëŠ” ì ˆì‚­)\n",
    "        if stft_img.shape[1] < config.target_time_bins:\n",
    "            padding = np.zeros((stft_img.shape[0], config.target_time_bins - stft_img.shape[1]))\n",
    "            stft_img = np.concatenate((stft_img, padding), axis=1)\n",
    "        else:\n",
    "            stft_img = stft_img[:, :config.target_time_bins]\n",
    "        stft_images.append(stft_img)\n",
    "    return np.stack(stft_images, axis=0)\n",
    "\n",
    "def window_to_raw_signal(window: pd.DataFrame, config: Config) -> np.ndarray:\n",
    "    \"\"\"ìœˆë„ìš°ì—ì„œ Raw ì‹ í˜¸(3ì±„ë„) ìƒì„±\"\"\"\n",
    "    values = window[['x', 'y', 'z']].values.T  # shape: (3, L)\n",
    "    target_raw_length = int(config.window_duration_seconds * config.fs)\n",
    "    if values.shape[1] != target_raw_length:\n",
    "        values = resample(values, target_raw_length, axis=1)\n",
    "    return values\n",
    "\n",
    "def save_data_for_split(class_name: str, split_name: str, windows: List[pd.DataFrame], metadata: List[Dict], config: Config):\n",
    "    \"\"\"ì§€ì •ëœ splitì˜ ìœˆë„ìš°ë“¤ì„ STFTì™€ Raw ì‹ í˜¸ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥\"\"\"\n",
    "    if not windows:\n",
    "        print(f\"  â© No windows to save for class '{class_name}', split '{split_name}'.\")\n",
    "        return\n",
    "\n",
    "    stft_tensors, raw_tensors = [], []\n",
    "    for window in windows:\n",
    "        resampled = resample_window(window, config)\n",
    "        if not resampled.empty:\n",
    "            stft_tensors.append(window_to_stft_image(resampled, config))\n",
    "            raw_tensors.append(window_to_raw_signal(resampled, config))\n",
    "\n",
    "    # STFT ì €ì¥\n",
    "    stft_dir = os.path.join(config.output_stft_dir, split_name)\n",
    "    os.makedirs(stft_dir, exist_ok=True)\n",
    "    stft_path = os.path.join(stft_dir, f\"{class_name}_stft_tensors.npy\")\n",
    "    np.save(stft_path, np.stack(stft_tensors))\n",
    "\n",
    "    # Raw ì‹ í˜¸ ì €ì¥\n",
    "    raw_dir = os.path.join(config.output_raw_dir, split_name)\n",
    "    os.makedirs(raw_dir, exist_ok=True)\n",
    "    raw_path = os.path.join(raw_dir, f\"{class_name}_raw_tensors.npy\")\n",
    "    np.save(raw_path, np.stack(raw_tensors))\n",
    "\n",
    "    print(f\"  ğŸ’¾ Saved {class_name}/{split_name}: {len(windows)} windows ({len(stft_tensors)} STFT, {len(raw_tensors)} Raw)\")\n",
    "    \n",
    "    # ë©”íƒ€ë°ì´í„° ì €ì¥\n",
    "    meta_df = pd.DataFrame(metadata)\n",
    "    meta_filename = f\"{class_name}_window_metadata_{split_name}.csv\"\n",
    "    meta_df_path = os.path.join(config.output_raw_dir, meta_filename)\n",
    "    meta_df.to_csv(meta_df_path, index=False)\n",
    "    print(f\"  ğŸ“ Saved metadata: {meta_df_path}\")\n",
    "\n",
    "#####################################\n",
    "# 4. ë°ì´í„° ì²˜ë¦¬ ì›Œí¬í”Œë¡œìš° í•¨ìˆ˜\n",
    "#####################################\n",
    "\n",
    "def generate_windows_for_class(class_name: str, files: Dict[str, str], config: Config, \n",
    "                               augment_splits: Dict[str, int] = {}) -> Tuple[Dict[str, list], List[Dict]]:\n",
    "    \"\"\"\n",
    "    í´ë˜ìŠ¤ì— ì†í•œ ëª¨ë“  íŒŒì¼ì— ëŒ€í•´ ìœˆë„ìš°ë¥¼ ìƒì„±í•˜ê³ , ì§€ì •ëœ splitì— ì¦ê°• ì ìš©\n",
    "    augment_splits: {'train': 5, 'val': 1} ì²˜ëŸ¼ ì¦ê°•í•  splitê³¼ ê³„ìˆ˜ë¥¼ ì§€ì •\n",
    "    \"\"\"\n",
    "    class_windows = {'train': [], 'val': [], 'test': []}\n",
    "    class_metadata = []\n",
    "\n",
    "    for file_id, file_path in files.items():\n",
    "        print(f\"    ğŸ“„ Processing file: {file_id}\")\n",
    "        data = load_data(file_path)\n",
    "        time_segments = get_time_segments_by_blocks(data, config)\n",
    "\n",
    "        for split, segments in time_segments.items():\n",
    "            for seg_idx, (start_time, end_time) in enumerate(segments):\n",
    "                block_data = data.loc[start_time:end_time]\n",
    "                if block_data.empty: continue\n",
    "\n",
    "                atoms = group_atoms(block_data)\n",
    "                windows = create_sliding_windows(atoms, config.window_size_atoms, config.step)\n",
    "                \n",
    "                # ì›ë³¸ ìœˆë„ìš° ì¶”ê°€\n",
    "                class_windows[split].extend(windows)\n",
    "                \n",
    "                # ë©”íƒ€ë°ì´í„° ê¸°ë¡\n",
    "                for win_idx, window in enumerate(windows):\n",
    "                    class_metadata.append({\n",
    "                        \"class\": class_name, \"file\": file_id, \"split\": split, \"block_index\": seg_idx,\n",
    "                        \"window_idx\": win_idx, \"start_time\": window.index[0], \"end_time\": window.index[-1],\n",
    "                        \"is_augmented\": False\n",
    "                    })\n",
    "                \n",
    "                # ì¦ê°• ì ìš©\n",
    "                augment_factor = augment_splits.get(split, 0)\n",
    "                if augment_factor > 0:\n",
    "                    augmented_wins = []\n",
    "                    for window in windows:\n",
    "                        augmented_wins.extend(augment_window(window, augment_factor))\n",
    "                    class_windows[split].extend(augmented_wins)\n",
    "                    print(f\"      â• Augmented {split} with {len(augmented_wins)} windows (factor={augment_factor})\")\n",
    "\n",
    "    return class_windows, class_metadata\n",
    "\n",
    "def run_processing(config: Config):\n",
    "    \"\"\"Train/Val/Test ë°ì´í„°ì…‹ì„ ìƒì„±. Train setì˜ abnormal_1,2ëŠ” ì¦ê°•\"\"\"\n",
    "    print(\"\\nğŸš€ Starting Data Processing (Train/Val/Test)\")\n",
    "    for class_name, files in config.all_files.items():\n",
    "        print(f\"  ğŸ”¹ Processing class: {class_name}\")\n",
    "        \n",
    "        # abnormal_1, 2ì˜ train splitì—ë§Œ ì¦ê°• ì ìš©\n",
    "        augment_config = {}\n",
    "        if class_name in config.classes_to_augment:\n",
    "            augment_config = {'train': 5}\n",
    "            print(f\"    âœ¨ Augmentation will be applied to 'train' split.\")\n",
    "\n",
    "        all_windows, all_metadata = generate_windows_for_class(class_name, files, config, augment_splits=augment_config)\n",
    "        \n",
    "        for split in ['train', 'val', 'test']:\n",
    "            split_windows = all_windows[split]\n",
    "            split_metadata = [m for m in all_metadata if m['split'] == split]\n",
    "            save_data_for_split(class_name, split, split_windows, split_metadata, config)\n",
    "\n",
    "#####################################\n",
    "# 5. ê²°ê³¼ í™•ì¸ ë° ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜\n",
    "#####################################\n",
    "\n",
    "def print_sample_counts(config: Config):\n",
    "    \"\"\"ê° split ë””ë ‰í† ë¦¬ë³„ ìƒ˜í”Œ ìˆ˜ ì¶œë ¥\"\"\"\n",
    "    splits_to_check = ['train', 'val', 'test']\n",
    "    class_names = list(config.all_files.keys())\n",
    "    \n",
    "    print(\"\\nğŸ“Š Sample Count Summary\")\n",
    "    print(\"â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
    "    print(f\"{'Split':<10} | {'Class':<12} | {'STFT':>6} | {'Raw':>6}\")\n",
    "    print(\"â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
    "\n",
    "    for split in splits_to_check:\n",
    "        for cls in class_names:\n",
    "            stft_path = os.path.join(config.output_stft_dir, split, f\"{cls}_stft_tensors.npy\")\n",
    "            raw_path = os.path.join(config.output_raw_dir, split, f\"{cls}_raw_tensors.npy\")\n",
    "            \n",
    "            stft_count = len(np.load(stft_path)) if os.path.exists(stft_path) else 0\n",
    "            raw_count = len(np.load(raw_path)) if os.path.exists(raw_path) else 0\n",
    "            \n",
    "            if stft_count > 0 or raw_count > 0:\n",
    "                print(f\"{split:<10} | {cls:<12} | {stft_count:6d} | {raw_count:6d}\")\n",
    "    print(\"â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d91d3376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Starting Data Processing (Train/Val/Test)\n",
      "  ğŸ”¹ Processing class: normal\n",
      "    ğŸ“„ Processing file: normal_1\n",
      "    ğŸ“„ Processing file: normal_2\n",
      "    ğŸ“„ Processing file: normal_3\n",
      "    ğŸ“„ Processing file: normal_4\n",
      "    ğŸ“„ Processing file: normal_5\n",
      "    ğŸ“„ Processing file: normal_6\n",
      "    ğŸ“„ Processing file: normal_7\n",
      "    ğŸ“„ Processing file: normal_8\n",
      "    ğŸ“„ Processing file: normal_9\n",
      "    ğŸ“„ Processing file: normal_10\n",
      "    ğŸ“„ Processing file: normal_11\n",
      "    ğŸ“„ Processing file: normal_12\n",
      "    ğŸ“„ Processing file: normal_13\n",
      "    ğŸ“„ Processing file: normal_14\n",
      "    ğŸ“„ Processing file: normal_15\n",
      "    ğŸ“„ Processing file: normal_16\n",
      "    ğŸ“„ Processing file: normal_17\n",
      "    ğŸ“„ Processing file: normal_18\n",
      "    ğŸ“„ Processing file: normal_19\n",
      "    ğŸ“„ Processing file: normal_20\n",
      "  ğŸ’¾ Saved normal/train: 1904 windows (1904 STFT, 1904 Raw)\n",
      "  ğŸ“ Saved metadata: processed_data_raw/normal_window_metadata_train.csv\n",
      "  ğŸ’¾ Saved normal/val: 156 windows (156 STFT, 156 Raw)\n",
      "  ğŸ“ Saved metadata: processed_data_raw/normal_window_metadata_val.csv\n",
      "  ğŸ’¾ Saved normal/test: 156 windows (156 STFT, 156 Raw)\n",
      "  ğŸ“ Saved metadata: processed_data_raw/normal_window_metadata_test.csv\n",
      "  ğŸ”¹ Processing class: abnormal_1\n",
      "    âœ¨ Augmentation will be applied to 'train' split.\n",
      "    ğŸ“„ Processing file: abnormal_1_1\n",
      "      â• Augmented train with 180 windows (factor=5)\n",
      "      â• Augmented train with 180 windows (factor=5)\n",
      "    ğŸ“„ Processing file: abnormal_1_2\n",
      "      â• Augmented train with 180 windows (factor=5)\n",
      "      â• Augmented train with 180 windows (factor=5)\n",
      "      â• Augmented train with 180 windows (factor=5)\n",
      "      â• Augmented train with 45 windows (factor=5)\n",
      "    ğŸ“„ Processing file: abnormal_1_3\n",
      "      â• Augmented train with 180 windows (factor=5)\n",
      "      â• Augmented train with 180 windows (factor=5)\n",
      "      â• Augmented train with 180 windows (factor=5)\n",
      "      â• Augmented train with 0 windows (factor=5)\n",
      "  ğŸ’¾ Saved abnormal_1/train: 1584 windows (1584 STFT, 1584 Raw)\n",
      "  ğŸ“ Saved metadata: processed_data_raw/abnormal_1_window_metadata_train.csv\n",
      "  ğŸ’¾ Saved abnormal_1/val: 8 windows (8 STFT, 8 Raw)\n",
      "  ğŸ“ Saved metadata: processed_data_raw/abnormal_1_window_metadata_val.csv\n",
      "  ğŸ’¾ Saved abnormal_1/test: 8 windows (8 STFT, 8 Raw)\n",
      "  ğŸ“ Saved metadata: processed_data_raw/abnormal_1_window_metadata_test.csv\n",
      "  ğŸ”¹ Processing class: abnormal_2\n",
      "    âœ¨ Augmentation will be applied to 'train' split.\n",
      "    ğŸ“„ Processing file: abnormal_2_1\n",
      "      â• Augmented train with 180 windows (factor=5)\n",
      "      â• Augmented train with 180 windows (factor=5)\n",
      "      â• Augmented train with 180 windows (factor=5)\n",
      "      â• Augmented train with 180 windows (factor=5)\n",
      "      â• Augmented train with 180 windows (factor=5)\n",
      "      â• Augmented train with 180 windows (factor=5)\n",
      "      â• Augmented train with 165 windows (factor=5)\n",
      "      â• Augmented train with 180 windows (factor=5)\n",
      "      â• Augmented train with 180 windows (factor=5)\n",
      "      â• Augmented train with 105 windows (factor=5)\n",
      "    ğŸ“„ Processing file: abnormal_2_2\n",
      "      â• Augmented train with 180 windows (factor=5)\n",
      "      â• Augmented train with 180 windows (factor=5)\n",
      "      â• Augmented train with 180 windows (factor=5)\n",
      "      â• Augmented train with 180 windows (factor=5)\n",
      "      â• Augmented train with 180 windows (factor=5)\n",
      "      â• Augmented train with 45 windows (factor=5)\n",
      "  ğŸ’¾ Saved abnormal_2/train: 2832 windows (2832 STFT, 2832 Raw)\n",
      "  ğŸ“ Saved metadata: processed_data_raw/abnormal_2_window_metadata_train.csv\n",
      "  ğŸ’¾ Saved abnormal_2/val: 14 windows (14 STFT, 14 Raw)\n",
      "  ğŸ“ Saved metadata: processed_data_raw/abnormal_2_window_metadata_val.csv\n",
      "  ğŸ’¾ Saved abnormal_2/test: 14 windows (14 STFT, 14 Raw)\n",
      "  ğŸ“ Saved metadata: processed_data_raw/abnormal_2_window_metadata_test.csv\n",
      "  ğŸ”¹ Processing class: abnormal_3\n",
      "    ğŸ“„ Processing file: abnormal_3_1\n",
      "    ğŸ“„ Processing file: abnormal_3_2\n",
      "  ğŸ’¾ Saved abnormal_3/train: 1955 windows (1955 STFT, 1955 Raw)\n",
      "  ğŸ“ Saved metadata: processed_data_raw/abnormal_3_window_metadata_train.csv\n",
      "  ğŸ’¾ Saved abnormal_3/val: 165 windows (165 STFT, 165 Raw)\n",
      "  ğŸ“ Saved metadata: processed_data_raw/abnormal_3_window_metadata_val.csv\n",
      "  ğŸ’¾ Saved abnormal_3/test: 165 windows (165 STFT, 165 Raw)\n",
      "  ğŸ“ Saved metadata: processed_data_raw/abnormal_3_window_metadata_test.csv\n",
      "  ğŸ”¹ Processing class: abnormal_4\n",
      "    ğŸ“„ Processing file: abnormal_4_3\n",
      "    ğŸ“„ Processing file: abnormal_4_4\n",
      "    ğŸ“„ Processing file: abnormal_4_5\n",
      "  ğŸ’¾ Saved abnormal_4/train: 2249 windows (2249 STFT, 2249 Raw)\n",
      "  ğŸ“ Saved metadata: processed_data_raw/abnormal_4_window_metadata_train.csv\n",
      "  ğŸ’¾ Saved abnormal_4/val: 190 windows (190 STFT, 190 Raw)\n",
      "  ğŸ“ Saved metadata: processed_data_raw/abnormal_4_window_metadata_val.csv\n",
      "  ğŸ’¾ Saved abnormal_4/test: 189 windows (189 STFT, 189 Raw)\n",
      "  ğŸ“ Saved metadata: processed_data_raw/abnormal_4_window_metadata_test.csv\n",
      "\n",
      "ğŸ“Š Sample Count Summary\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Split      | Class        |   STFT |    Raw\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "train      | normal       |   1904 |   1904\n",
      "train      | abnormal_1   |   1584 |   1584\n",
      "train      | abnormal_2   |   2832 |   2832\n",
      "train      | abnormal_3   |   1955 |   1955\n",
      "train      | abnormal_4   |   2249 |   2249\n",
      "val        | normal       |    156 |    156\n",
      "val        | abnormal_1   |      8 |      8\n",
      "val        | abnormal_2   |     14 |     14\n",
      "val        | abnormal_3   |    165 |    165\n",
      "val        | abnormal_4   |    190 |    190\n",
      "test       | normal       |    156 |    156\n",
      "test       | abnormal_1   |      8 |      8\n",
      "test       | abnormal_2   |     14 |     14\n",
      "test       | abnormal_3   |    165 |    165\n",
      "test       | abnormal_4   |    189 |    189\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. ì„¤ì • ê°ì²´ ìƒì„±\n",
    "    config = Config()\n",
    "\n",
    "    # 2. Train/Val/Test ë°ì´í„°ì…‹ ìƒì„±\n",
    "    # (abnormal_1, abnormal_2ì˜ train setì€ ë‚´ë¶€ì ìœ¼ë¡œ ì¦ê°•ë¨)\n",
    "    run_processing(config)\n",
    "\n",
    "    # 3. ìµœì¢… ê²°ê³¼ í™•ì¸\n",
    "    print_sample_counts(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11eb8540",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
